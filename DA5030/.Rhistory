unite( col = 'y-month', year, month, sep = '-') %>%
ggplot() +
geom_line( mapping = aes( x = tper, y = avg_price_sq_ft, group = y-month))
df_st %>%
unite( col = 'y-month', year, month, sep = '-')
ggplot(df_st) +
geom_line( mapping = aes( x = tper, y = avg_price_sq_ft))
setwd("/Users/jiamingxu/OneDrive - Northeastern University/Spring 2022/DA5030")
df <- read_csv("diabetes.csv")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
df <- read_csv("diabetes.csv")
str(df)
df %>%
mutate( x = seq(min(Age), max(Age), length.out = nrow(df)),
norm_age = dnorm(x, mean = mean(Age), sd = sd(Age))) %>%
ggplot() +
geom_histogram(mapping = aes(x = Age, y = ..density..), binwidth = 2, fill = 'white', color = 'black')  +
geom_line( mapping = aes(x = x, y = norm_age), color = 'red') +
labs(title = "Age frequency histogram plot of patients",
x = 'Age', y = 'Frequency')
if(!require(devtools)) install.packages("devtools")
devtools::install_github("kassambara/ggpubr")
library(ggpubr)
shapiro.test(df$Age)
if(!require(devtools)) install.packages("devtools")
devtools::install_github("kassambara/ggpubr")
library(ggpubr)
shapiro.test(df$Age)
zscore <- function(x){
return ((x - mean(x))/sd(x))
}
z_names <- str_c(names(df), '_z')
df_z <- sapply(df, function(x){cbind( zscore(x))}) %>% as_tibble()
names(df_z) <- z_names
df_outliers <- apply(df_z, 2,function(x) {
df[abs(x)>2,] %>%
cbind(z = x[abs(x)>2])
})
df_outliers
df_outliers_distribution <- sapply(df_z, function(x) sum(abs(x) > 2))
ggplot()+
geom_bar( mapping=aes(x = names(df_outliers_distribution), y = df_outliers_distribution), stat="identity") +
labs( title = "Number of outliters in each variable", x = "Variable", y = "Count") +
coord_flip()
df_z
zscore(df$Pregnancies)
zscore(df$Glucose)
lapply(df_z, function(x){})
lapply(df_z, function(x){df[abs(x) > 2, ]})
df_outliers <- lapply(df_z,function(x) {
df[abs(x)>2,] %>%
cbind(z = x[abs(x)>2])
})
df_outliers <- lapply(df_z,function(x) {
df[abs(x)>2,] %>%
cbind(z = x[abs(x)>2])
})
df_outliers
zscore <- function(x){
return ((x - mean(x))/sd(x))
}
df_z <- sapply(df, function(x){cbind( zscore(x))}) %>% as_tibble()
df_z$Outcome <- df$Outcome
zscore <- function(x){
return ((x - mean(x))/sd(x))
}
df_z <- sapply(df, function(x){cbind( zscore(x))}) %>% as_tibble()
df_z$Outcome <- df$Outcome
df_z
str(df_z)
set.seed(1)
# Filter out two outcomes then randomly select 15% of observations in each subset.
# Then bind rows of train and test samples together, data frame reordered.
oc0 <- df_z %>% filter(Outcome == 0)
sample0 <- sample.int( nrow(oc0), floor(0.15 * nrow(oc0)), replace = FALSE)
oc1 <- df_z %>% filter(Outcome == 1)
sample1 <- sample.int( nrow(oc1), floor(0.15 * nrow(oc1)), replace = FALSE)
sample_test <- rbind(oc0[sample0, ], oc1[sample1, ])
sample_train <- rbind(oc0[-sample0, ], oc1[-sample1, ])
sample_test_label <- sample_test$Outcome    # argument cl takes only factor as an input of knn()
sample_train_label <- sample_train$Outcome
sample_test <- sample_test[ ,-9]    # Drop outcome columns
sample_train <- sample_train[ ,-9]
sum(df$Outcome == 0)/nrow(df) # Number of 0 in original df.
sum(sample_test_label == 0)/(length(sample0) + length(sample1)) # Number of 0 in test data set.
nrow(sample_test)/ nrow(df)
library(gmodels)
getMode <- function(x) {
## Took and modified from https://www.delftstack.com/howto/r/mode-in-r/.
u <- unique(x)
return (u[which.max(tabulate(match(x, u)))])
}
my_knn <- function( train, test, cl, k){
modes_output <- vector()
for (i in 1:nrow(test)) {
a <- sweep( as.matrix(train), 2, as.matrix(test[i, ])) %>% as_tibble()
top_index <- sort(rowSums(a^2), index.return=T)$ix[1:k]
mode <- sample_train_label[top_index] %>% getMode()
modes_output <- append(modes_output, mode)
}
return (modes_output)
}
goal <- tibble( Pregnancies = 4,
Glucose = 118,
BloodPressure = 50,
SkinThickness = 30,
Insulin = 78,
BMI = 35,
DiabetesPedigreeFunction = 0.279,
Age = 29)
goal_z <- (goal - colMeans(df[, -9])) / sapply(df_z[, -9], function(x) sd(x))
my_pred <- my_knn(sample_train, sample_test, sample_train_label, 5)
CrossTable(my_pred, sample_test_label)
my_knn(sample_train, goal_z, sample_train_table, 5)
library(class)
set.seed(1)
df_pred <- knn( train = sample_train,
test = sample_test,
cl = sample_train_label, k=5)
CrossTable(df_pred, sample_test_label)
knn( train = sample_train,
test = goal_z,
cl = sample_train_label, k=5)
library(gmodels)
getMode <- function(x) {
## Took and modified from https://www.delftstack.com/howto/r/mode-in-r/.
u <- unique(x)
return (u[which.max(tabulate(match(x, u)))])
}
my_knn <- function( train, test, cl, k){
modes_output <- vector()
for (i in 1:nrow(test)) {
a <- sweep( as.matrix(train), 2, as.matrix(test[i, ])) %>% as_tibble()
top_index <- sort(rowSums(a^2), index.return=T)$ix[1:k]
mode <- sample_train_label[top_index] %>% getMode()
modes_output <- append(modes_output, mode)
}
return (modes_output)
}
goal <- tibble( Pregnancies = 4,
Glucose = 118,
BloodPressure = 50,
SkinThickness = 30,
Insulin = 78,
BMI = 35,
DiabetesPedigreeFunction = 0.279,
Age = 29)
goal_z <- (goal - colMeans(df[, -9])) / sapply(df_z[, -9], function(x) sd(x))
my_pred <- my_knn(sample_train, sample_test, sample_train_label, 5)
CrossTable(my_pred, sample_test_label)
my_knn(sample_train, goal_z, sample_train_table, 5)
set.seed(1) # Make sure knn gives the same results.
acc_rate <- vector()
for (k in 2:8) {
df_pred <-  knn(sample_train,
sample_test,
sample_train_label, k= k)
acc_rate <- append(acc_rate, sum(df_pred == sample_test_label)/ length(sample_test_label))
}
ggplot( ) +
geom_line( mapping = aes(x = seq(2,8), y = acc_rate)) +
geom_point( mapping = aes( x = seq(2, 8), y = acc_rate), color = 'red') +
labs( title = "Prediction accuracy as a function of k", x = 'k', y = 'Accuracy (%)') +
scale_y_continuous(labels = scales::percent)
set.seed(1) # Make sure knn gives the same results.
acc_rate <- vector()
for (k in 2:8) {
df_pred <-  knn(sample_train,
sample_test,
sample_train_label, k= k)
acc_rate <- append(acc_rate, sum(df_pred == sample_test_label)/ length(sample_test_label))
}
ggplot( ) +
geom_line( mapping = aes(x = seq(2,8), y = acc_rate)) +
geom_point( mapping = aes( x = seq(2, 8), y = acc_rate), color = 'red') +
labs( title = "Prediction accuracy as a function of k", x = 'k', y = 'Accuracy (%)') +
scale_y_continuous(labels = scales::percent)
library(dplyr)
library(MASS)
df <- as_tibble(Boston)
target_data <- df$medv
train_data <- df[, -ncol(df)]
train_data_norm <- sapply(train_data, function(x) ((x - min(x))/ (max(x) - min(x)))) %>% as_tibble()
# Test if normalization performed.
sapply(train_data_norm, function(x) range(x))
knn.reg <- function(new_data, target_data, train_data, k ){
if (k < 4) {stop("K must greater than 3.")}
prices <- vector()
for (i in 1:nrow(new_data)) {
a <- sweep( as.matrix(train_data), 2, as.matrix(new_data[i, ])) %>% as_tibble()
top_index <- sort(rowSums(a^2), index.return=T)$ix[1:k]
weight_factor <- c(3,2,rep(1, k-2))
price <- sum(target_data[top_index] * weight_factor / sum(weight_factor))
prices <- append(prices, price)
}
return (prices)
}
new_data <- tibble( crim = 0.15560, zn = 12.5,
indus = 7.87, chas = 0,
nox = 0.524, Rm = 6.173, age = 96.1,
dis = 5.9505, rad = 5, tax = 311,
pratio = 15.2, black = 396.9, lstat = 19.5)
new_data_norm <- (new_data - sapply(train_data, min)) / (sapply(train_data, max) - sapply(train_data, min))
knn.reg( new_data_norm, target_data, train_data_norm, 20)
set.seed(1)
test_data_index <- sample.int( nrow(train_data_norm), floor(0.1 * nrow(train_data_norm)),
replace = FALSE)
sample_test <- train_data_norm[test_data_index, ]
sample_train <- train_data_norm[-test_data_index, ]
sample_train_label <- target_data[-test_data_index]
sample_test_label <- target_data[test_data_index]
knnreg_pred <- knn.reg( sample_test, sample_train_label, sample_train, 5)
my_mse <- mean(( knnreg_pred - sample_test_label)^2)
my_mse
summary(df_z)
library(tidyverse)
df <- read_csv('kc_house_data.csv')
df
df_st <- df %>%
mutate( year_month = format(date, "%Y-%b")) %>%
group_by( year_month) %>%
summarise( avg_price_sq_ft = mean(price/sqft_living)) %>%
separate(year_month, c("year", "month"), sep = '-') %>%
mutate( tper = seq(1:length(year))) %>%
relocate( tper, .before = year)
df_st
df_st <- df %>%
mutate( year_month = format(date, "%Y-%b")) %>%
group_by( year_month) %>%
summarise( avg_price_sq_ft = mean(price/sqft_living)) %>%
arrange( year_month) %>%
separate(year_month, c("year", "month"), sep = '-') %>%
mutate( tper = seq(1:length(year))) %>%
relocate( tper, .before = year)
df_st
df_st <- df %>%
mutate( year_month = format(date, "%Y-%b")) %>%
group_by( year_month) %>%
summarise( avg_price_sq_ft = mean(price/sqft_living)) %>%
arrange( year_month)
df_st
df_st$year_month %>% as.Date()
df_st$year_month[1] %>% as.Date()
df_st$year_month[1]
as.Date(df_st$year_month[1], format = "%Y-%b")
?as.Date
as.Date(df_st$year_month, format = "%Y-%b")
as.Date(df_st$year_month, format = "%Y")
as.Date(df_st$year_month, format = "%Y-%B")
as.Date(df_st$year_month, format = "%b")
as.Date(df_st$year_month, format = "%Y-%m")
as.Date(df_st$year_month, format = "%Y")
df_st <- df %>%
mutate( year_month = format(date, "%Y%b")) %>%
group_by( year_month) %>%
summarise( avg_price_sq_ft = mean(price/sqft_living)) %>%
arrange( year_month)
separate(year_month, c("year", "month"), sep = '-') %>%
mutate( tper = seq(1:length(year))) %>%
relocate( tper, .before = year)
df_st <- df %>%
mutate( year_month = format(date, "%Y%b")) %>%
group_by( year_month) %>%
summarise( avg_price_sq_ft = mean(price/sqft_living)) %>%
arrange( year_month)
df_st$year_month
df_st$year_month %>% as.Date(format='$y$b')
df_st$year_month %>% as.Date(format='%Y%b')
df_st$year_month %>% as.Date(format='%Y')
df_st$year_month %>% as.Date.POSIXct(format='%Y%b')
df_st$year_month %>% as.Date.POSIXct()
df_st$year_month[1] %>% as.Date.POSIXct()
df_st <- df %>%
mutate( year_month = format(date, "%Y-%m")) %>%
group_by( year_month) %>%
summarise( avg_price_sq_ft = mean(price/sqft_living)) %>%
arrange( year_month)
df_st$year_month
df_st$year_month %>% as.Date(format='%Y-%m')
df_st$year_month %>% as.Date(format='%Y')
as.Date('2020-01', format = '%Y-%m')
as.Date('202001', format = '%Y%m')
as.Date('2020jan', format = '%Y%m')
as.Date("1jan1960", format = '%b%m%Y')
as.Date("1jan1960", format = '%b%b%Y')
x <- c("1jan1960", "2jan1960", "31mar1960", "30jul1960")
z <- as.Date(x, "%d%b%Y")
z
x
as.Date("1jan1960", "%d%b%Y")
as.Date(df_st$year_month, "%Y-%m")
as.Date("1jan1960", "%d%b%Y")
as.Date("1jan1960", "%d%m%Y")
as.Date("1111960", "%d%m%Y")
as.Date("01111960", "%d%m%Y")
as.Date("01-11-1960", "%d-%m-%Y")
df_st$year_month[1]
as.Date("2014-05", "%Y-%m")
as.Date("2014-05-02", "%Y-%m-%b")
as.Date("2014-05-02", "%Y-%m-%d")
df_st <- df %>%
mutate( year_month = format(date, "%Y-%m")) %>%
group_by( year_month) %>%
summarise( avg_price_sq_ft = mean(price/sqft_living)) %>%
separate(year_month, c("year", "month"), sep = '-') %>%
arrange( month) %>%
mutate( tper = seq(1:length(year))) %>%
relocate( tper, .before = year)
df_St
df_st
df_st <- df %>%
mutate( year_month = format(date, "%Y-%m")) %>%
group_by( year_month) %>%
summarise( avg_price_sq_ft = mean(price/sqft_living)) %>%
separate(year_month, c("year", "month"), sep = '-') %>%
arrange( year,month) %>%
mutate( tper = seq(1:length(year))) %>%
relocate( tper, .before = year)
df_st
df_st %>%
unite( col = 'y-month', year, month, sep = '-')
ggplot(df_st) +
geom_line( mapping = aes( x = tper, y = avg_price_sq_ft))
df_st %>%
unite( col = 'y-month', year, month, sep = '-')
ggplot(df_st) +
geom_line( mapping = aes( x = y-month, y = avg_price_sq_ft))
df_st %>%
unite( col = 'y-month', year, month, sep = '-')
ggplot(df_st) +
geom_line( mapping = aes( x = 'y-month', y = avg_price_sq_ft))
df_st %>%
ggplot(df_st) +
geom_line( mapping = aes( x = tper, y = avg_price_sq_ft))
ggplot(df_st) +
geom_line( mapping = aes( x = tper, y = avg_price_sq_ft))
pred <- (df_st$avg_price_sq_ft[ nrow(df_st)-3: nrow(df_st)] * c(4,3,1) ) / sum (c(4,3,1))
df_st$avg_price_sq_ft[ nrow(df_st)-3: nrow(df_st)]
df_st$avg_price_sq_ft[ (nrow(df_st)-3): nrow(df_st)]
df_st$avg_price_sq_ft[ (nrow(df_st)-2): nrow(df_st)]
df_st$avg_price_sq_ft[ (nrow(df_st)-2): nrow(df_st)] * * c(1 ,3,4) )
df_st$avg_price_sq_ft[ (nrow(df_st)-2): nrow(df_st)] * c(1 ,3,4)
weight_factor = c(1, 3, 4) # ascending indexing.
pred <- (df_st$avg_price_sq_ft[ nrow(df_st)-3: nrow(df_st)] *weight_factor ) / sum (weight_factor)
pred <- (df_st$avg_price_sq_ft[ (nrow(df_st)-2): nrow(df_st)] *weight_factor ) / sum (weight_factor)
weight_factor = c(1, 3, 4) # ascending indexing.
pred <- (df_st$avg_price_sq_ft[ (nrow(df_st)-2): nrow(df_st)] *weight_factor ) / sum (weight_factor)
pred
pred <- sum(df_st$avg_price_sq_ft[ (nrow(df_st)-2): nrow(df_st)] *weight_factor ) / sum (weight_factor)
pred
pred
df_st$month
ggplot(df_st) +
geom_line( mapping = aes( x = tper, y = avg_price_sq_ft)) +
ylab("Average price per squared foot of living room ($/ft^2)") +
xlab("Time period (month from 2014 May)")
Create weight_factor vector contains factors for last three months. Calculate weighted prediction for next month. (2015-Jun)
library(dplyr)
library(MASS)
df <- as_tibble(Boston)
target_data <- df$medv
train_data <- df[, -ncol(df)]
train_data_norm <- sapply(train_data, function(x) ((x - min(x))/ (max(x) - min(x)))) %>% as_tibble()
# Test if normalization performed.
sapply(train_data_norm, function(x) range(x))
knn.reg <- function(new_data, target_data, train_data, k ){
if (k < 4) {stop("K must greater than 3.")}
prices <- vector()
for (i in 1:nrow(new_data)) {
a <- sweep( as.matrix(train_data), 2, as.matrix(new_data[i, ])) %>% as_tibble()
top_index <- sort(rowSums(a^2), index.return=T)$ix[1:k]
weight_factor <- c(3,2,rep(1, k-2))
price <- sum(target_data[top_index] * weight_factor / sum(weight_factor))
prices <- append(prices, price)
}
return (prices)
}
new_data <- tibble( crim = 0.15560, zn = 12.5,
indus = 7.87, chas = 0,
nox = 0.524, Rm = 6.173, age = 96.1,
dis = 5.9505, rad = 5, tax = 311,
pratio = 15.2, black = 396.9, lstat = 19.5)
new_data_norm <- (new_data - sapply(train_data, min)) / (sapply(train_data, max) - sapply(train_data, min))
knn.reg( new_data_norm, target_data, train_data_norm, 20)
train_data_normã€1
train_data_norm[1]
train_data_norm[1,]
knn.reg( train_data_norm[1], target_data, train_data_norm, 20)
knn.reg( train_data_norm[1, ], target_data, train_data_norm, 20)
target_data[1]
knn.reg( train_data_norm[2, ], target_data, train_data_norm, 20)
target_data[2]
knn.reg( train_data_norm[2, ], target_data, train_data_norm, 5)
knn.reg( train_data_norm[1, ], target_data, train_data_norm, 5)
knn.reg( train_data_norm[6, ], target_data, train_data_norm, 5)
target_data[6]
new_data <- tibble( crim = 0.15560, zn = 12.5,
indus = 7.87, chas = 0,
nox = 0.524, Rm = 6.173, age = 96.1,
dis = 5.9505, rad = 5, tax = 311,
pratio = 15.2, black = 396.9, lstat = 19.5)
new_data_norm <- (new_data - sapply(train_data, min)) / (sapply(train_data, max) - sapply(train_data, min))
knn.reg( new_data_norm, target_data, train_data_norm, 5)
sapply(train_data, max)
sapply(train_data, min)
which[train_data[, 1] == 88.9762]
library(dplyr)
library(MASS)
df <- as_tibble(Boston)
target_data <- df$medv
train_data <- df[, -ncol(df)]
train_data_norm <- sapply(train_data, function(x) ((x - min(x))/ (max(x) - min(x)))) %>% as_tibble()
# Test if normalization performed.
sapply(train_data_norm, function(x) range(x))
knn.reg <- function(new_data, target_data, train_data, k ){
if (k < 4) {stop("K must greater than 3.")}
prices <- vector()
for (i in 1:nrow(new_data)) {
a <- sweep( as.matrix(train_data), 2, as.matrix(new_data[i, ])) %>% as_tibble()
top_index <- sort(rowSums(a^2), index.return=T)$ix[1:k]
weight_factor <- c(3,2,rep(1, k-2))
price <- sum(target_data[top_index] * weight_factor / sum(weight_factor))
prices <- append(prices, price)
}
return (prices)
}
new_data <- tibble( crim = 0.15560, zn = 12.5,
indus = 7.87, chas = 0,
nox = 0.524, Rm = 6.173, age = 96.1,
dis = 5.9505, rad = 5, tax = 311,
pratio = 15.2, black = 396.9, lstat = 19.5)
new_data_norm <- (new_data - sapply(train_data, min)) / (sapply(train_data, max) - sapply(train_data, min))
knn.reg( new_data_norm, target_data, train_data_norm, 5)
set.seed(1)
test_data_index <- sample.int( nrow(train_data_norm), floor(0.1 * nrow(train_data_norm)),
replace = FALSE)
sample_test <- train_data_norm[test_data_index, ]
sample_train <- train_data_norm[-test_data_index, ]
sample_train_label <- target_data[-test_data_index]
sample_test_label <- target_data[test_data_index]
knnreg_pred <- knn.reg( sample_test, sample_train_label, sample_train, 5)
my_mse <- mean(( knnreg_pred - sample_test_label)^2)
my_mse
knnreg_pred
sample_test_label
( knnreg_pred - sample_test_label)^2
c(3,2,rep(1, 5-2))
library(klaR)
data(iris)
nrow(iris)
summary(iris)
head(iris)
testidx <- which(1:length(iris[, 1]) %% 5 == 0)
iristrain <- iris[-testidx,]
iristest <- iris[testidx,]
nbmodel <- NaiveBayes(Species~., data=iristrain)
?data
?NaiveBayes
Species~.
Species~.
Species
Species~
Species~.
Species~.
nbmodel
NaiveBayes(Long~., data=iristrain)
?eval
iris
colnames(iris)
NaiveBayes(Petal.Length~., data=iristrain)
NaiveBayes(Petal~., data=iristrain)
NaiveBayes("Petal.Width~.", data=iristrain)
NaiveBayes("Petal.Width"~., data=iristrain)
NaiveBayes(x = Petal.Width~., data=iristrain)
NaiveBayes(Species~., data=iristrain)
NaiveBayes(x = Species~., data=iristrain)
?NaiveBayes
NaiveBayes(grouping = Species~., data=iristrain)
mpg
mpgs
carmpg
cars
head(cars)
clear
library(dataset)
datasets::airquality
head(datasets::airquality)
df <- iris
df
colnames(df)
colnames(df) <- c("SLength","SWidth", "PLength","PWidth","Species")
df <- as_tibble(df)
head(df)
NaiveBayes(SLength~., data = iristrain)
NaiveBayes(SLength~., data = df)
factor(df$SLength)
df$SLength <- factor(df$SLength)
NaiveBayes(SLength~., data = df)
NaiveBayes(Species~., data = df)
table(df$Species, df$SLength)
table(df$Species, df$SWidth)
apply(table(df$Species, df$SWidth), 1, sum)
nbmodel
prediction <- predict(nbmodel, iristest[,-5])
table(prediction$class, iristest[,5])
iristest[, -5]
?predict
nbmodel
prediction
prediction$class
prediction$class
